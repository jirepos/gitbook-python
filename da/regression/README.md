# 회귀분석
회귀 분석은 둘 이상의 변수 간의 관계를 보여주는 통계적 방법이다. 일반적으로 그래프로 표현되는 이 방법은 종속 변수와 독립 변수 간의 관계를 테스트한다. 일반적으로 독립 변수는 종속 변수에 따라 변경되며 회귀 분석은 해당 변경에서 가장 중요한 요소에 대한 답을 찾으려고 시도한다. 


## 참고 

[회귀분석의 이해 #1](https://brunch.co.kr/@gimmesilver/64)    
[회귀분석의 이해 #2](https://brunch.co.kr/@gimmesilver/65)    
[회귀분석의 이해 #3](https://brunch.co.kr/@gimmesilver/66)    
[회귀분석의 이해 #4](https://brunch.co.kr/@gimmesilver/69)    



* 실측치와 회귀 모형의 예측치(조건부 평균) 사이의 값을 잔차(residual)라고 한다. 
* 회귀 모형이 원본 데이터를 잘 대표하는 것을 보통 잘 적합(fit)했다라고 표현
* 회귀 모형을 잘 적합시키려면 잔차가 정규분포이어야 한다. 
* 통계학 교재에서는 '정규성 가정을 만족해야 한다'라고 설명한다. 
* 잔차가 정규 분포가 되도록 회귀 모형을 만들어야 모형이 데이터에 잘 적합한 것이라고 얘기할 수도 있다. 


**잔차가 중요함** 

회귀 분석을 접하는 많은 사람들이 이 '정규성 가정'을 잘못 생각해서 '잔차'의 분포가 아니라 분석대상이 되는 관측 데이터의 분포가 정규분포가 되어야 한다라고 착각하곤 한다. 

그래서 데이터를 분석할 때 전체 아파트 가격이나 연봉 데이터의 분포가 어떤 형태인지를 확인한다. 하지만 이건 정규성을 잘못 이해한 것이다. 실제로는 조건 내에서의 데이터 분포(이것을 조건부 확률분포라고 부른다)가 정규분포가 되는지 확인해야 한다.  다만, 이것을 직접 확인하기가 불가능하기 때문에 잔차의 분포를 확인하는 것이다. 


실전에서 회귀 분석을 위해 요구하는 가정을 모두 만조하는 회귀 모델은 거의 없다. 여러가지 이유가 있겠지만, 현실에서는 확보할 수 있는 데이터에 한계가 있기 때문이다. 

어쩔 수 없이 지금 보유한 정보 내에서 최선의 결과를 만들 수 밖에 없다. 다시 말해, 이론적으로는 정규성, 독립성, 등분산성을 만족해야 하지만 현실에서는 이것을 완전히 만족하기는 어려우니 적한 선에서 타협한다. 


회귀 분석을 할 때는 다음과 같은 점들을 주의해야 한다. 
* 회귀 분석의 예측치와 실측치 사이의 차이인 잔차의 분포가 최대한 정규 분포에 가까워야 한다. 
* 잔차는 조건에 따라 편향되지 않고 분산이 일정해야 한다. 
* 특정 조건에서 잔차값이 크게 튀는 아웃라이어가 없어야 한다. 


**최소제곱법**    


회귀 모형은 각 조건 변수와 조건이 평균에 미치는 영향력을 나타내는 가중치를 곱한 값들의 합으로 표현한다. 이 가중치값들을 '회귀 계수(regression coefficient)'라고 부른다. 

회귀 계수를 추정하고 나면 데이터들의 평균을 가로지르는 선을 그릴 수 있다. 

이 회귀 계수(직선의 기울기)는 어떻게 구할 수 있을까?

여러가지 방법이 있겠지만 일반적으로 회귀 분석에서 사용하는 방법은 '최소제곱법(Least Square Method)'이다.  이런 이름이 붙은 이유는 이 기법이 잔차의 '제곱의 합이 최소'가 되는 직선(엄밀히 말하면 직선을 그리는 함수)을 찾는 방법이기 때문이다. 


회귀 분석이 최소제곱법 만 있는 것은 아니다. 

**OLS**    
그래서 모든 관련 기법을 통칭하는 의미에서 '회귀'와 최초에 언급했던 회귀 분석 기법을 구분하기 위해서, 처음에 소개한 회귀 분석 기법을 '(특별한 기교를 더하지 않고)평범한 최소 제곱법을 통해 조건부 평균을 구하는 회귀'라는 의미에서 Odrdinary Least Squres(OLS) regression'이라고 부른다. 


**잔차 분석**     
회귀 모형을 통해 구한 조건부 평균이 실제 데이터를 잘 대표하는 값이 되려면 잔차가 정규성, 독립성, 등분산성이라는 가정을 만족해야 한다.  




## 학습할 사이트 
[Multiple Linear Regression](https://www.sfu.ca/~mjbrydon/tutorials/BAinPy/10_multiple_regression.html)      
[Supervised Learning: Regression](https://youtu.be/2q6wprv-Vho)      
[Regression Analysis StatsModel](https://youtu.be/z_BXANUOjJY)     


## 참고
[데이터 사이언스 스쿨](https://datascienceschool.net/03%20machine%20learning/04.02%20%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D%EC%9D%98%20%EA%B8%B0%EC%B4%88.html)     
[Statsmodel boston 예제](https://ysyblog.tistory.com/119)    




















